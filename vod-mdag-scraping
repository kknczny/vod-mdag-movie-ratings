from bs4 import BeautifulSoup
from urllib.request import urlopen
import ssl
import time
import sys
# import asyncio
import pandas as pd
from imdb import Cinemagoer

pd.options.mode.chained_assignment = None       #  Suppres Pandas SettingWithCopyWaring
pd.options.display.max_columns = 10

class AddRatingsFromPage():

    def __init__(
            self,
            url: str = "https://vod.mdag.pl/pl/filmy",
            test_subset: int = None
    ):
        self.url = url
        self.test_subset = test_subset

    def scrap_page(self):
        titles = pd.DataFrame()
        context = ssl.SSLContext(ssl.PROTOCOL_TLS)

        with urlopen(self.url, context=context) as response:
            soup = BeautifulSoup(response, "html.parser")
        
        titles['title'] = [value.string for value in soup.find_all("div", "moviebox-desc")]
        titles['title_pl'] = [value.string for value in soup.find_all("div", "moviebox-title")]

        ##add also a step to go into movie subpage based on link and get additional information such as year
        
        if self.test_subset is not None:
            titles = titles.head(self.test_subset)
    
        self.titles = titles

        if len(titles) == 1:
            print(f"Found on page: {len(titles)} title")
        elif len(titles) > 1:
            print(f"Found on page: {len(titles)} titles")
        else:
            print("No titles found on page")

        return titles
    
    def get_ratings(self):
        
        titles = self.titles
        stdout_counter = 1
        ia = Cinemagoer()

        print("Starting obtaining ratings")
        start = time.time()

        for index, title in titles['title'].items():
            
            sys.stdout.write(f"Progress: downloading rating for item #{stdout_counter} out of {len(titles)}.\r")

            imdb_movies = ia.search_movie(title.strip())
            movie_id = str(imdb_movies[0].movieID)
            movie = ia.get_movie(movie_id)

            details_list = {
                'imdb_title' : 'str(imdb_movies[0])',
                'year' : 'str(movie[\'year\'])',        ##add also comparison for year once obtained for vod movies
                'rating' : 'movie[\'rating\']',
                'votes' : 'str(movie[\'votes\'])',
                'countries' : '\', \'.join(movie[\'countries\'])',
                'imdb_id': 'movie_id'
                }
            
            for column, func in details_list.items():
                try:
                    titles.at[index, column] = eval(func)
                except KeyError:
                    titles.at[index, column] = None
                    continue

            sys.stdout.flush()
            stdout_counter += 1
        
        end = time.time()
        minutes, seconds = divmod(end-start, 60)
        print(f"Obtaining ratings finished. It took: {minutes} minutes and {seconds} seconds.")

        # titles['names_match']: str(titles.at[index, 'title']==titles.at[index, 'imdb_title'])
        titles.index += 1
        titles.sort_values('rating', ascending=False, inplace=True)
        
        print(titles)

        titles.to_csv("Ratings.csv")
    
    def get_ratings_from_url(self):
        self.scrap_page()
        self.get_ratings()
        

if __name__ == "__main__":
    pd.options.display.max_rows = 200
    vod_mdag = AddRatingsFromPage(test_subset=None)
    vod_mdag.get_ratings_from_url()
