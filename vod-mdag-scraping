from bs4 import BeautifulSoup
from urllib.request import urlopen
import ssl
import time
import sys
import asyncio
import pandas as pd
from imdb import Cinemagoer

pd.options.mode.chained_assignment = None       #  Suppres Pandas SettingWithCopyWaring
pd.options.display.max_columns = 10

class AddRatingsFromPage():

    def __init__(
            self,
            url: str = "https://vod.mdag.pl/pl/filmy",
            test_subset: int = 13
    ):
        self.url = url
        self.test_subset = test_subset

    def scrap_page(self):
        titles = pd.DataFrame()

        context = ssl.SSLContext(ssl.PROTOCOL_TLS)

        with urlopen(self.url, context=context) as response:
            soup = BeautifulSoup(response, "html.parser")
        
        titles['title'] = [value.string for value in soup.find_all("div", "moviebox-desc")]
        titles['title_pl'] = [value.string for value in soup.find_all("div", "moviebox-title")]

        ##add also a step to go into movie subpage based on link and get additional information such as year
        
        if self.test_subset is not None:
            titles = titles.head(self.test_subset)
    
        self.titles = titles

        if len(titles) == 1:
            print(f"Found on page: {len(titles)} title")
        elif len(titles) > 1:
            print(f"Found on page: {len(titles)} titles")
        else:
            print("No titles found on page")

    
        return titles
    
    @staticmethod
    async def get_details(titles, index, ia, imdb_movies, stdout_counter):

        sys.stdout.write(f"Progress: Downloading rating for item no {stdout_counter} out of {len(titles)}.\r")

        movie_id = str(imdb_movies[0].movieID)

        movie = await ia.get_movie(movie_id)

        titles.at[index, 'imdb_title'] = str(imdb_movies[0])
        titles.at[index, 'names_match'] = str(titles.at[index, 'title']==titles.at[index, 'imdb_title'])    ##add also comparison for year once obtained for vod movies

        titles.at[index, 'imdb_id'] = movie_id
        
        titles.at[index, 'year'] = str(movie['year'])
        # titles['countries']

        titles.at[index, 'rating'] = movie['rating']
        titles.at[index, 'votes'] = str(movie['votes'])

        sys.stdout.flush()

        return titles


    def get_ratings(self):
        
        titles = self.titles
        stdout_counter = 1
    
        print("Starting obtaining ratings")
        start = time.time()
        ia = Cinemagoer()
        list_of_tasks = []

        for index, title in titles['title'].items():
           
            imdb_movies = ia.search_movie(title.strip())

            list_of_tasks.append(self.get_details(titles, index, ia, imdb_movies, stdout_counter))

            stdout_counter += 1
        
        asyncio.gather(*list_of_tasks)

        end = time.time()

        print(f"Obtaining ratings finished. It took: {end-start} seconds.")
        
        # titles.index += 1
        # titles.sort_values('rating', ascending=False)
        print(*list_of_tasks)
        print(titles)

        # titles.to_csv("Ratings.csv")
    
    def get_ratings_from_url(self):
        self.scrap_page()
        self.get_ratings()
        

if __name__ == "__main__":
    vod_mdag = AddRatingsFromPage(test_subset=3)
    vod_mdag.get_ratings_from_url()